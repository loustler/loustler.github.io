---
layout: post
title:  "[BigData 기초] 1. 빅데이터의 특성과 그 기술"
date:   2020-04-13 22:16:44 +0900
categories: [data_eng]
tags : [data, bigdata]
---

첫 회사에서 데이터 엔지니어링의 경험을 하고 빅데이터를 자연스레 접하였지만,

이에 대해 부족함이 있어 공부를 하고 포스팅을 하고자 한다.

<!--more-->

# 빅데이터의 특성
## 빅데이터의 3V
1. **크기(Volume)**
  - 데이터의 양을 의미
  - 보통 페타바이트(PB)를 넘어서 엑사바이트(EB) 심지어는 제타바이트(ZB), 요타바이트(YB)까지의 데이터의 양을 의미
1. **속도(Velocity)**
  - 데이터가 수신되거나 처리되는 속도를 의미
  - 실시간처리(real-time, stream 등)와 장기적인 접근(batch를 비롯한 Data Mining, Machine Learning 등)가 있음
1. **다양성(Variety)**
  - 데이터의 종류가 무수히 많은 것을 의미
  - 정형, 반정형, 비정형 데이터
  - 정형(Structured Data): 말그대로 구조화된 데이터로 형식을 갖춘 데이터. RDB의 스키마를 생각하면 된다.
  - 반정형(Semi-Structured Data): 정형보다 구조화가 덜 된 것으로 JSON, XML 등과 같은 것을 예로 들 수 있음. Schemaless Data라고도 함
  - 비정형(Unstructured Data): 이미지, 동영상, 오디오 등

### 빅데이터의 4V
1. **3V** + Value(가치)
  - 데이터의 가치를 의미
1. **3V** + Veracity(정확성)
  - 데이터의 정확성을 의미
1. **3V** + Visualization(시각화)

등등

### 빅데이터의 5V
- **3V** + Value(가치) + Veracity(정확성)

# 일반적인 빅데이터의 기술

1. Hadoop(Spark)
1. NoSQL DB
1. 분산처리를 위한 분산시스템
  - 정통적인 DW에서도 대량의 데이터를 처리가 가능하나, 확장성을 비롯하여 데이터가 늘어나는 속도를 고려했을 때 Hadoop을 이용해 DW의 부하를 줄임

# 데이터 파이프라인(Data Pipeline)
1. 데이터 수집
1. 스트림처리 및 배치처리
1. 분산 스토리지
1. 분산 데이터 처리
1. Workflow 관리

## 데이터 수집
기존 RDB를 비롯하여 로그, 이벤트 데이터 등의 데이터를

- 스트림(stream)
  - 지속적으로 생성되는 데이터를 끊임없이 보내 수집하는 방법
- 벌크(bulk)
  - 기존에 존재하는 데이터를 정리해서 추출하여 수집하는 방법
  - DB, 파일 서버 등

형태로 수집

## 스트림(stream) 처리와 배치(batch)처리
- 스트림 처리
  - 스트리밍 데이터를 실시간으로 처리하기 위한 것으로 stream processing 이라고 함
  - 장기적인 데이터 분석에는 유용하지 않음
     - 연 단위의 데이터 분석과 같은 장기간의 데이터 분석에는 어려움이 있음
- 배치 처리
  - 대량의 데이터를 처리해야 하므로 분산 시스템이 좋음
  - 장기적인 데이터 분석을 위해 대량의 데이터를 가공하는 것

## 분산 스토리지
수집된 데이터들을 저장하는 곳

데이터를 저장하는 방법으로 S3와 같은 Object Storage 형태도 있음

NoSQL DB도 사용가능하며, 많은 데이터의 읽기/쓰기 처리를 하는데 적합하며 확장성이 높은 것을 선택해야 됨

## 분산 데이터 처리
분산 스토리지에 저장된 데이터를 처리하는 것

Hadoop의 MR(MapReduce)를 사용하는 이유가 이런 이유

주요 역할은

- 나중에 분석하기 쉽도록 데이터를 가공 및 저장

데이터 집계에 있어서 주로 SQL을 사용하며 이를 지원하기 위해서 2가지 방법이 있다

1. Query Engine 도입
   - Hive 와 같은 것
1. 외부의 DW 제품을 사용
   - AWS Redshift, GCS BigQuery 등

## Workflow 관리
전체 데이터 파이프라인의 동작을 관리하기 위함

매일 정해진 시간에 배치처리를 스케줄링하고 오류가 발생했을 때 관리자에게 통보

크든 작든 데이터를 처리하다가 보면 에러가 발생할 수 있기 때문에 이를 다시 처리하고 오류를 처리하기 위해서 필수적으로 도입해야 됨
