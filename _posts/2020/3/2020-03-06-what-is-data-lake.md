---
layout: post
title:  "Data Lake란"
date:   2020-03-06 22:00:00 +0900
categories: [data_eng]
tags : [data lake]
---

이전 포스트들로 [DW와 Data Lake의 차이](/data_eng/trend-dw-to-data-lake/), [DW에서 Data Lake로 가는 이유](/data_eng/diff-data_lake-data_warehouse/) 그리고 [DW에 대해 공부한 것](/data_eng/what-is-dw/)을 정리했었다.

이번에는 Data Lake에 대해서 알아보려 한다.

<!--more-->

Dake Lake는 DW가 발전한(?) 형태다

기존의 DW는 일종의 스키마와 같은 형태로 정형화된 데이터를 가지고 있다면,

Data Lake는 비정형화 데이터 즉, 아무런 정해진 형태가 없는 데이터(Raw data)를 가지고 있다.

이전에 [DW와 Data Lake의 차이](/data_eng/trend-dw-to-data-lake/)에서 살펴본 DW와 Data Lake의 차이를 다시 한 번 살펴보자

| | Data Warehouse | Data Lake |
|---|---|---|
|데이터|트랜잭션 시스템, 운영 데이터베이스 및 사업부서 애플리케이션의 관계형 데이터 | IoT 디바이스, 웹사이트, 모바일앱, 소셜 미디어 및 기업 애플리케이션의 비관계형 및 관계형 데이터|
|스키마|데이터 웨어하우스 구현 전에 설계됨(Schema on write)|분석 시에 쓰여짐(Schema on read)|
|가격/성능| 고비용의 스토리지를 사용하여 가장 빠른 결과를 얻음|저비용의 스토리지를 사용하여 쿼리 결과의 속도가 빨라짐|
|데이터 품질|신뢰할 수 있는 중앙 버전 역할을 하는 고도의 큐레이트된 데이터| 큐레이트될 수 있거나 될 수 없는 모든 데이터(즉, 원시데이터)|
|사용자| Business Analyst, Data Scientist, Data Engineer | Data Scientist, Data Engineer, Business Anlayst|
|분석| 배치 보고, BI 및 시각화 | 기계 학습, 예측 분석, 데이터 디스커버리 및 프로파일링|

이전에 정리했던 것을 다시 살펴보았다.

차이점은 이렇고 Data Lake에 대해서 계속 이어가자면,

Data Lake가 이렇게 비정형 데이터(Raw data)를 저장하게 되므로써 저장할 수 있는 데이터의 종류가 많아지고 그 사이즈가 커지면서

이에 따라 다양한 기술 요소들을 제공해주어야 하게 되었다.

이런 기술들은

1. Bulk Data Movement / Dynamic Data Movement
  - 데이터 수집 기술로 배치, 스트림 등 다양한 실시간 서비스를 보장하는 소스데이이터의 수집이 가능해야 함
  - 다양한 형태의 데이터에 대한 수집 파이프라인 생성과 실행 및 흐름 관리도 가능해야 됨
  - 수집 파이프라인은 빠르고 높은 신뢰도 그리고 유연해야 함
1. Data Access Infrastructure
  - 쉽고 빠른 데이터 수집을 위해 데이터 사용자, Data Lake 관리 플랫폼, 데이터 소스 간의 어떠한 하드코딩도 없이 연결되어야 됨
  - ODBC, JDBC 등 다양한 데이터 소스에 대한 Buil-In된 연결 어댑터를 가지고 있어야 됨
  - 커스텀 연결 어댑터 또한 제공되어야 함
1. Composite Data Framework
  - 다양한 이기종 데이터 소스로부터 연결 어댑터 및 각 데이터 소스의 메타정보를 이용해 마치 하나의 저장소를 이용하는 것 같아야 됨
  - 데이터 스키마 정보를 이용해 데이터를 미리 수집하지 않고 필요할 때, Join/Merge를 통해 새로운 데이터세트를 만들 수 있어야 됨
1. Data Quality
  - 품질 관리 기술을 통해 수집한 데이터에 대한 품질 모니터링 및 프로파일링 정보(데이터 분포, 통계정보, 샘플 등)를 제공해야 됨
  - 데이터 검증 및 중복 데이터 제거가 가능해야 됨
  - 개인정보 비식별화, 데이터 표준화, 결측치 보정, 이상치 탐지 등 데이터 정제 작업도 여기에 해당됨
1. Metadata Management
  - 메타데이터: 데이터에 대한 정의와 언제, 어떻게, 누구에 의해 작성되고 수정되었는 지와 같은 것들
  - 이 메타데이터를 관리하여야 하며, 메타데이터를 이용하여 언제든지 데이터 추적이 가능하여야 하고 이를 이용해 권한 관리도 할 수 있음
1. Master Data Definition and control
  - 마스터 데이터를 유지하고 무결성 보장을 위해서 마스터 데이터의 계와 속성, 계층구조, 처리규칙 등의 메타데이터를 관리해야 됨
  - 주요기능으로 데이터 가져오기/내보내기, 버전관리, 동기화 등
1. Self-Service Data Preparation
  - 가장 트렌디한 기술
  - 머신러닝/딥러닝 을 통해 데이터 정제/변환/탐색을 자동화하여 사용자가 쉽고 빠르게 데이터를 준비할 수 있게 해줌

등이 있다.

또한 Data Lake는 DW와 달리 분석을 할 때 데이터의 형태가 정해지게 되면서 원하는 형태로 데이터를 만들어서 분석할 수도 있다.

그래서 Data Lake에는 카탈로그(Catalog) 라는 기능이 필요한데, 이 카탈로그는 말그대로 카탈로그다. 데이터가 어디에 저장이 되어 있는지 카탈로그를 만들어놓고,

분석이 필요할 때 이 카탈로그를 통해서 데이터에 접근하는 것이다.

그리고 보통 데이터 레이크를 사용하기 위해 HDFS를 사용한다. HDFS와 같은 Distributed File system을 이용하여 신뢰성, 안정성, 범용성 등을 확보하는 모양이다.
